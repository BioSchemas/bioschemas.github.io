---
layout: joining
title: Google Summer of Code 2018
---

<div itemscope itemtype="http://schema.org/Organization">
    <div id="main_content_wrap" class="outer">
        <section id="main_content" class="inner">




<h1>Google Summer of Code 2018</h1>

<p>
The Bioschemas community is happy to participate in Google Summer of Code (GSoC) for the first time. Our mentors are active Bioschemas contributors and many of them have successfully participated in the GSoC with other open source communities. We look forward to engaging students in practical projects and together contribute to build the Bioschemas open source community.
</p>

<p>
This web page gives an overview of project ideas we are offering to students who wish to spend their summer working with us. We are looking for enthusiastic developers willing to engage and work together with our mentors on the projects listed below.
</p>

<h2>About Bioschemas</h2>
<p><a href="/">Bioschemas</a> aims to improve data discovery and interoperability in the life sciences. It does this by encouraging people in the life sciences to use <a href="https://schema.org/">schema.org</a> markup, so that their websites and services contain consistently structured, machine processable information. This structured information then makes it easier to discover, collate, and analyse distributed data.</p>
            
<p>Schema.org defines a range of properties and types, which describe a wide range of things that can be found on the Web - from concert tickets to automobile repair shops. The Bioschemas community is a global team that generates <a href="specifications">best practise guidelines</a> for how to use the types and properties defined by schema.org to describe life sciences web pages and services. Where schema.org is unable to cover the more technical aspects of the life sciences, Bioschemas proposes widely deployed terms from the life sciences community that could be incorporated into schema.org.</p>

<p>The projects proposed on this page are designed to help our community extend its infrastructure and tooling, thereby enabling improved data discovery through wider adoption of the markup. The projects can be grouped into tools to support data creation and tools to support data utilization.</p>

<h3>Organisation Administrators</h3>
<ul>
    <li>Alasdair Gray</li>
    <li>Rafael Jimenez</li>
</ul>
            
<h3>Mentors</h3>
<ul>
    <li>Dominique Batista</li>
    <li>Niall Beard</li>
    <li>Manuel Bernal Llinares</li>
    <li>Justin Clark-Casey</li>
    <li>Alexander Garcia</li>
    <li>Leyla J Garcia</li>
    <li>Olga Giraldo</li>
    <li>Alasdair Gray</li>
    <li>Federico Lopez</li>
    <li>Kenneth McLeod</li>
    <li>Sarala Wimalaratne</li>
</ul>

<h2>Project Ideas</h2>

<h3>Bioschemas Common Crawl</h3>
<p>Crawl websites to create a Bioschemas markup dataset that can be used by other projects.</p>
<h4>Description</h4>
<p>Various projects (such as Buzzbang and SPARQL over Bioschemas) want to make data across the whole of life sciences easier to find and use. To do this using Bioschemas, they will need a crawl of all the webpages that host Bioschemas markup. Rather than each project producing this crawl separately, it will be more efficient if they can share a common dataset, which may be supplemented with other datasets such as <a href="http://commoncrawl.org">Common Crawl</a>.</p>
<h4>Expected outcomes</h4>
<ul><li>A crawler for Bioschemas data, likely based upon an existing web crawler such as <a href="http://nutch.apache.org/">Apache Nutch</a>.</li>
<li>A downloadable RDF dataset containing the crawl.</li>
<li>A periodically refreshed crawl.</li></ul>
<h4>Skills</h4>
<ul><li>Java</li>
<li>DevOps</li>
<li>Bonus: RDF and any experience with Triplestores</li></ul>
<h4>Difficulty</h4>
<ul><li>Hard</li></ul></ul>
<h4>Mentors</h4>
<ul><li>Justin Clark-Casey</li></ul></ul>
<h3>Buzzbang</h3>
<p>An open-source Google-like Bioschemas-enabled search engine.</p>
<h4>Description</h4>
<p>Even though life sciences database projects have produced many sophisticated query interfaces, simple free text search, in the style of Google's search frontend, is still extremely  popular for finding scientific data. The Buzzbang project looks to leverage Bioschemas markup to provide this kind of simple search interface to return more relevant and interconnected results than is possible with just the analysis of free text. This project encompasses work to improve both the Buzzbang web frontend and the backend operations to create the search index.</p>
<h4>Expected outcomes</h4>
<ul><li>Improved backend indexing for Buzzbang, possibly replacing some existing custom crawl scripts with processing of a common crawl produced by the "Bioschemas Common Crawl" project.</li>
<li>Improved frontend for the Buzzbang project, with display of <a href="https://developers.google.com/search/docs/guides/mark-up-content">Google-style rich results</a> generated from Bioschemas markup.</li></ul>
<h4>Skills</h4>
<ul><li>Java</li>
<li>Python</li>
<li>Solr</li>
<li>Flask</li></ul>
<h4>Mentors</h4>
<ul><li>Justin Clark-Casey</li></ul></ul>
<h4>Difficulty</h4>
<ul><li>Hard</li></ul></ul>

<h4>References</h4>
<ul><li><a href="http://buzzbang.science/">http://buzzbang.science/</a></li>
<li><a href="https://github.com/justinccdev/bsbang-crawler/tree/dev">https://github.com/justinccdev/bsbang-crawler/tree/dev</a></li>
<li><a href="https://github.com/justinccdev/bsbang-frontend">https://github.com/justinccdev/bsbang-frontend</a></li></ul>

<h3>SPARQL over Bioschemas</h3>
<p>Implement a SPARQL interface over crawled Bioschemas data</p>
<h4>Description</h4>
<p>The <a href="http://lod-cloud.net/">Linked Open Data cloud</a> is a vast distributed graph of interconnected structured information, a large proportion of which comes from the life sciences. This information is expressed in a common data structure called the <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">Resource Description Framework</a> (RDF), which enables distributed querying using the <a href="https://en.wikipedia.org/wiki/SPARQL">SPARQL</a> standard. Bioschemas markup itself can be expressed as RDF. This project would create a SPARQL endpoint that spans crawled Bioschemas data from the "Bioschemas Common Crawl" project, to join it to the Linked Open Data cloud and make this data easier to combine with other information.</p>
<h4>Skills</h4>
<ul><li>RDF</li>
<li>OWL</li>
<li>SPARQL</li>
<li>Triplestore databases</li></ul>
<h4>Mentors</h4>
<ul><li>Federico Lopez</li>
<li>Leyla Garcia</li>
<li>Alexander Garcia</li></ul>
<h4>Difficulty</h4>
<ul><li>Hard</li></ul>
<h4>References</h4>
<ul><li><a href="https://github.com/BioSchemas/bioschemas-nutch-indexer">https://github.com/BioSchemas/bioschemas-nutch-indexer</a></li></ul></ul>

<h3>Map2Model</h3>
<p>Automating the generation and publication of Bioschema's specifications from best practise guidelines.</p>
<h4>Description</h4>
<p>This tool supports our community in the creation and display of the specification documents that define a profile. To support widespread collaboration, we use Google Sheets for the definition of a profile. The Map2Model tool merges the contents of the Google Sheet with pre-existing types from Schema.org, before converting the result into markdown which can then be rendered on the community website for use by other Bioschemas tools and the wider life science world.</p>
<h4>Expected outcomes</h4>
<ul><li>Convert Map2Model from a standalone process to a web service that is run in response to a request from the community.</li>
<li>Make the Map2Model process more robust.</li>
<li>Automatically publish the output as a versioned specification on the Bioschema's web page.</li>
<li>Generate machine processable constraints defining the profile.</li></ul>
<h4>Skills</h4>
<ul><li>Web services</li>
<li>Devops</li>
<li>Java or Python</li>
<li>RDF (desirable but not essential)</li></ul>
<h4>Mentors</h4>
<ul><li>Alasdair Gray</li>
<li>Kenneth McLeod</li></ul>
<h4>Rate difficulty</h4>
<ul><li>Medium</li></ul></ul>
<h4>References</h4>
<ul><li><a href="https://github.com/BioSchemas/map2model">https://github.com/BioSchemas/map2model</a> </li>
<li><a href="http://bioschemas.org/specifications/">http://bioschemas.org/specifications/</a></li></ul>

<h3>Markup Builder</h3>
<p>A web application for prototyping markup against the Bioschemas profiles.</p>
<h4>Description</h4>
<p>This web application supports users in the creation of Bioschemas compliant markup required for inclusion on their web resource.</p>
<ul><li>Bioschemas provides profiles for schema.org mark-up in order to structure and expose life-sciences metadata on the web. Each profile brings a list of allowed attributes with their constraints and properties. Some attributes are required, some are composite, some allow multiple values, some are under controlled vocabularies and some can even be all of that. We want to create a web application that assist users into the creation of their metadata structure, through dynamically generated forms, allowing an easier sharing over the web.</li></ul></ul>
<h4>Expected outcomes</h4>
<p>Needs:<p>
<ul><li>Help us get the profiles attributes properties loaded into the app from different file formats.</li>
<li>Help us build responsive widgets that can be re-used for different attributes and profiles.</li>
<li>Link these widgets to the relevant attributes in the JSON-LD output.</li></ul>
<p>Project results:</p>
<ul><li>Specifications files can be loaded into the app to dynamically generate forms.</li>
<li>The generated widgets allow to add new attributes to a JSON-LD variable based on loaded properties. The JSON-LD variable is displayed in real-time (without form validation).</li>
<li>The code should be importable as an AngularJS library in order to be reusable</li></ul>
<h4>Skills</h4>
<ul>
<li>Languages: JS / CSS / HTML</li>
<li>Formats: JSON-LD</li>
<li>Framework: AngularJS.</li></ul>
<h4>Mentors</h4>
<ul><li>Dominique Batista</li>
<li>Alasdair Gray</li></ul>
<h4>Rate difficulty</h4>
<ul><li>Medium+</li></ul>

<h3>Validata</h3>
<p>A web application for validating Bioschema's markup against the specifications.</p>
<h4>Description</h4>
<p>This web app supports users in testing whether their generated markup is compliant with the Bioschemas specifications. The validation engine currently supports machine processable constraint descriptions written in the Shape Expression (ShEx) language which capture the Bioschema profiles. The Validata app allows users to supply some markup which is then compared to the profiles and generates an error report to the user for the snippet of code they provide.</p>
<h4>Expected outcomes</h4>
Extend the existing system such that:
<ul><li>it supports JSON-LD;</li>
<li>it can validate an entire site; and,  </li>
<li>it is able to retrieve pages from an external URL so that they can be tested <i>in situ</i>.</li>
<li>Improve the user interactions with the application making it easier to use and simpler to act upon the validation reports.</li></ul>
<h4>Skills</h4>
<ul><li>Languages: JS/CSS/HTML</li>
<li>Formats: JSON-LD</li></ul>
<h4>Mentors</h4>
<ul><li>Alasdair Gray</li>
<li>Leyla Garcia</li>
<li>Kenneth McLeod</li></ul>
<h4>Rate difficulty</h4>
<ul><li>Medium+</li></ul>
<h4>References</h4>
<ul><li><a href="https://github.com/HW-SWeL/Validata">https://github.com/HW-SWeL/Validata</a> </li></ul>

<h3>Bioschemas4JATS</h3>
<p>How could we have infoboxes describing the content of a scientific publication? </p>
<h4>Description</h4>
<p>The Journal Article Tag Suite (JATS) is an XML format used to describe scientific literature published online. We want to define the representation of JATS data elements in schema.org and have this as an addition to BioSchemas. This projects requires an engaged critical thinker; the task at hand needs more analysis than coding. The student will analyze the JATS specification, determine what data elements from that specification describe the publication and the content and then, map these to Bioschemas. If needed, then the student will propose new data elements. If possible, the student will also design and implement the corresponding parser, making it easier to extract from JATS those data elements that are part of the resulting Bioschemas specification. </p>
<h4>Expected outcomes</h4>
<ul><li>Mapping JATS data elements to Bioschemas </li>
<li>Defining additional elements in Bioschemas that make it possible to describe a scientific publication </li>
<li>Bioschemas specification for the JATS format. </li>
<li>Parser, from JATS to Bioschemas4JATS</li></ul>
<h4>Skills</h4>
<ul><li>Curious and willing to learn</li>
<li>Basic knowledge of JSON-LD, XML</li>
<li>Basic to medium Python; how to write parsers, basic data wrangling. </li>
<li>Familiar with github</li></ul>
<h4>Mentors</h4>
<ul><li>Alexander Garcia</li>
<li>Olga Giraldo</li>
<li>Leyla Jael Garcia </li></ul>
<h4>Rate difficulty</h4>
<ul><li>Easy+ </li></ul>
<h4>References</h4>
<ul><li><a href="https://jats.nlm.nih.gov/">https://jats.nlm.nih.gov/</a></li></ul>




        </section>
    </div>
</div>
